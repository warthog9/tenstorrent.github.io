

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>User Guide &mdash; TT Buda  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/tt_theme.css?v=0bbfeaf8" />

  
    <link rel="shortcut icon" href="_static/favicon.png"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Reference" href="api.html" />
    <link rel="prev" title="Introduction to PyBuda" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://tenstorrent.github.io/">
    <img src="_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="toc.html">
    TT Buda
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introduction to PyBuda</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#framework-support">Framework Support</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#framwork-support-matrix">Framwork Support Matrix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pybuda-introduction">PyBuda Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#devices">Devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modules">Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-workload">Run Workload</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cpu-fallback">CPU Fallback</a></li>
<li class="toctree-l3"><a class="reference internal" href="#results">Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#saving-and-loading-models">Saving and Loading Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tenstorrent-device-image-tti-saving-loading">TensTorrent Device Image (TTI): Saving/Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-tti-targeting-supported-silicon-devices">Create TTI: Targeting Supported Silicon Devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-tti-targeting-custom-row-harvested-silicon-devices">Create TTI: Targeting Custom Row-Harvested Silicon Devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-tti-targeting-custom-device-descriptor">Create TTI: Targeting Custom Device Descriptor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#embedded-tti-loading">Embedded TTI Loading</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pybuda-automatic-mixed-precision">Pybuda Automatic Mixed Precision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#automatic-mixed-precision-amp">Automatic Mixed Precision (AMP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-defined-mixed-precision-configurations">User-Defined Mixed Precision Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-defined-intermediate-queues">User-Defined Intermediate Queues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-devices">Multiple Devices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#using-multiple-tenstorrent-devices">Using Multiple Tenstorrent Devices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pybuda-multi-model-support-embedded-applications-only">Pybuda Multi-Model Support (Embedded Applications Only)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#table-1-tt-smi-optional-arguments">Table 1. TT-SMI optional arguments.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tt-smi">TT-SMI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tt-smi-introduction">TT-SMI Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">Table 1. TT-SMI optional arguments.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#live-display-mode">Live Display Mode</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#table-2-live-display-keyboard-shortcuts">Table 2. Live display keyboard shortcuts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#cli-mode">CLI Mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dump-telemetry">Dump Telemetry</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#table-3-telemetry-dump-output-for-one-chip-in-spreadsheet-format">Table 3. Telemetry dump output for one chip in spreadsheet format</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#snapshot">Snapshot</a></li>
<li class="toctree-l3"><a class="reference internal" href="#warm-reset">Warm Reset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#warm-reset-mobo">Warm Reset Mobo</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples-of-pybuda-use-cases">Examples of PyBuda use cases</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="terminology.html">Terminology</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_user_guide.html">Advanced User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware.html">Hardware Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataformats.html">Data Formats and Math Fidelity</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer.html">Developer Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="toc.html">TT Buda</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="toc.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">User Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/user_guide.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="user-guide">
<h1>User Guide<a class="headerlink" href="#user-guide" title="Link to this heading"></a></h1>
<section id="framework-support">
<h2>Framework Support<a class="headerlink" href="#framework-support" title="Link to this heading"></a></h2>
<p>Pybuda itself is a standalone ML framework and has an API heavily inspired by Pytorch.  That said, it is often more convenient to run models that have already been written using another major framework.  This is why we support a Pybuda backend for TVM which allows many popular frameworks to target our pybuda compiler. We support many major frameworks that TVM supports including:</p>
<section id="framwork-support-matrix">
<h3>Framwork Support Matrix<a class="headerlink" href="#framwork-support-matrix" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Framework</p></th>
<th class="head"><p>PyBuda Wrapper Class</p></th>
<th class="head"><p>Support</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Pybuda</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.PyBudaModule</span></code></p></td>
<td><p>Native Support</p></td>
</tr>
<tr class="row-odd"><td><p>Pytorch</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.PyTorchModule</span></code></p></td>
<td><p>Supported</p></td>
</tr>
<tr class="row-even"><td><p>Tensorflow</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.TFModule</span></code></p></td>
<td><p>Supported</p></td>
</tr>
<tr class="row-odd"><td><p>Jax</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.JaxModule</span></code></p></td>
<td><p>Supported via <code class="docutils literal notranslate"><span class="pre">jax2tf</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Tensorflow Lite</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.TFLiteModule</span></code></p></td>
<td><p>Preliminary Support</p></td>
</tr>
<tr class="row-odd"><td><p>Onnx</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.OnnxModule</span></code></p></td>
<td><p>Preliminary Support</p></td>
</tr>
<tr class="row-even"><td><p>Tensorflow GraphDef</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pybuda.TFGraphDefModule</span></code></p></td>
<td><p>Preliminary Support</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="pybuda-introduction">
<h2>PyBuda Introduction<a class="headerlink" href="#pybuda-introduction" title="Link to this heading"></a></h2>
<p>A typical PyBuda flow has 4 steps:</p>
<ol class="arabic simple">
<li><p>Define devices to run workload on</p></li>
<li><p>Place modules from the workload onto devices</p></li>
<li><p>Run workload</p></li>
<li><p>Retrieve results</p></li>
</ol>
<p>PyBuda API and workflow is flexible enough that some of these steps can be merged, reordered, or skipped altogether, however it helps to work through this basic workflow to understand PyBuda concepts.</p>
<section id="devices">
<h3>Devices<a class="headerlink" href="#devices" title="Link to this heading"></a></h3>
<p>PyBuda makes it easy to distribute a workload onto a heterogenous set of devices available to you. This can be one or more
Tenstorrent devices, CPUs, or GPUs. Each device that will be used to run your workflow needs to be declared by creating the appropriate
device type and giving it a unique name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span> <span class="o">=</span> <span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>
<span class="n">cpu0</span> <span class="o">=</span> <span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, the first available device of the appropriate type will be allocated, but out-of-order allocations can be done
using the the optional id field.</p>
<p>The order in which the devices are created is important, because they are automatically connected into a pipeline of devices,
which will be explained in mode detail <a class="reference internal" href="#using-multiple-tenstorrent-devices"><span class="xref myst">further down</span></a>.</p>
<p>Each TTDevice can represent more than one hardware device, as described in <a class="reference internal" href="#multiple-devices"><span class="xref myst">multi-device section</span></a>.</p>
</section>
<section id="modules">
<h3>Modules<a class="headerlink" href="#modules" title="Link to this heading"></a></h3>
<p>A typical ML/AI workload consists of modules. PyBuda supports modules that are written in various <a class="reference internal" href="#framework-support"><span class="xref myst">frameworks</span></a>, such
as PyTorch, Tensorflow, and so on, as well as modules written in native PyBuda. Currently, all modules run on Tenstorrent devices, but
CPU and GPU devices can’t run PyBuda modules.</p>
<p>To run a module on a device, it needs to be “placed” on it</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
</pre></div>
</div>
<p>This tells PyBuda that module <code class="docutils literal notranslate"><span class="pre">mod</span></code> needs to be compiled and executed on device <code class="docutils literal notranslate"><span class="pre">tt0</span></code>. In this case, <code class="docutils literal notranslate"><span class="pre">mod</span></code> is a native PyBuda module. To
simiarly place a PyTorch module onto a Tenstorrent device, the module must be wrapped in a <a class="reference internal" href="api.html#pybuda.PyTorchModule"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">PyTorchModule</span></code></span></a> wrapper:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)))</span>
</pre></div>
</div>
</section>
<section id="run-workload">
<h3>Run Workload<a class="headerlink" href="#run-workload" title="Link to this heading"></a></h3>
<p>The running of the workload involves two parts, usually done in parallel - data feeding, and actual running.</p>
<p>To feed data into the device pipeline, simply push inputs into the first device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span> <span class="p">(</span><span class="n">input0</span><span class="p">,</span> <span class="n">input1</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
<p>This can be done in a separate thread, through a data-loader, or any other common way of feeding data into a workload pipeline. It is important
that at least one set of inputs has been pushed into the first device before attempting to compile and run the workload, because PyBuda compiler
requires a set of sample inputs to determine graph shapes, data formats, and other properties.</p>
<p>PyBuda provides all-in-one APIs for compiling and running workloads, <a class="reference internal" href="api.html#pybuda.run_inference"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_inference</span></code></span></a> and
<a class="reference internal" href="api.html#pybuda.run_training"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_training</span></code></span></a>, which both return a queue in which the results will be automatically pushed.
For inference, and simple training setups, this is the simplest way to get up and running.</p>
<p>Alternatively, the models can be compiled in a separate step, using the <a class="reference internal" href="api.html#pybuda.initialize_pipeline"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">initialize_pipeline</span></code></span></a> call,
which optioanlly takes sample inputs, if none have been pushed into the first device. Once the compilation has completed, the user
can run <a class="reference internal" href="api.html#pybuda.run_forward"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_forward</span></code></span></a> pass through the pipeline for inference, or a loop of
<a class="reference internal" href="api.html#pybuda.run_forward"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_forward</span></code></span></a>, <a class="reference internal" href="api.html#pybuda.run_backward"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_backward</span></code></span></a>, and <a class="reference internal" href="api.html#pybuda.run_optimizer"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">run_optimizer</span></code></span></a>
calls to manually implement a training loop:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acc_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>

        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">acc_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_optimizer</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="cpu-fallback">
<h3>CPU Fallback<a class="headerlink" href="#cpu-fallback" title="Link to this heading"></a></h3>
<p>If there are operators in the workload that are unsuppored by PyBuda, the user can create a CPUDevice and place module containing those
operators onto that CPUDevice. If enabled, PyBuda is capable of doing this automatically.</p>
<p>If a TTDevice contains unsuppored operators, during compilation, the device will be split into mupltiple devices (TTDevice and CPUDevice). If
the CPUDevice is at the front of the pipeline (i.e. the unsupported ops are in the first half of the graph), any inputs pushed to the TTDevice
will be redirected to the correct CPUDevice.</p>
<p>To enable CPU fallback:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">compiler_cfg</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_get_global_compiler_config</span><span class="p">()</span>
<span class="n">compiler_cfg</span><span class="o">.</span><span class="n">enable_tvm_cpu_fallback</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>Then place the module as normal:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;workload&quot;</span><span class="p">,</span> <span class="n">module_with_unsupported_ops</span><span class="p">))</span>
</pre></div>
</div>
<p>Push inputs and run:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
   <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input_tokens</span><span class="p">))</span>
   <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
   <span class="n">output</span> <span class="o">=</span> <span class="n">output_q</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="results">
<h3>Results<a class="headerlink" href="#results" title="Link to this heading"></a></h3>
<p>Typical inference runs produce inference outputs, and training runs produce parameter checkpoints. By default, PyBuda APIs for these workflows
create multiprocessing queues to which resulting tensors will be pushed to. Optionally, user can provide their own queues.</p>
<p>Reading these results is then as simple as popping data from the queues:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;run_direct&quot;</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output_q</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
<p>Output queues hold PyBuda tensors. For each PyBuda tensor, user can convert it back to original framework tensor using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output_in_tf</span> <span class="o">=</span> <span class="n">output_q</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_framework</span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Advanced training scenarios sometimes require accumulated gradients to be retrieved and analyzed. For those cases, PyBuda provides an
:py:<a class="reference internal" href="api.html#pybuda.get_parameter_gradients"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">API</span></code></span></a> that retrieves a dictionary of all currently accumulated gradients on a device. This can be used to
debug or analyze data, or even run a manual optimizer and push new weights onto the device.</p>
</section>
</section>
<section id="saving-and-loading-models">
<h2>Saving and Loading Models<a class="headerlink" href="#saving-and-loading-models" title="Link to this heading"></a></h2>
<p>In a simple training workflow, a checkpoint interval can be set, and every N optimization steps the current device state will be pushed into
the checkpoint queue. For more advanced use cases, a manual checkpoint can be retrieved using
<a class="reference internal" href="api.html#pybuda.get_parameter_checkpoint"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">get_parameter_checkpoint</span></code></span></a> API, which returns a dictionary of all parameters on a
device and their current values.</p>
<p>Such a dictionary can also be pushed back onto the device using <a class="reference internal" href="api.html#pybuda.update_device_parameters"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">update_device_parameters</span></code></span></a>.</p>
<section id="tenstorrent-device-image-tti-saving-loading">
<h3>TensTorrent Device Image (TTI): Saving/Loading<a class="headerlink" href="#tenstorrent-device-image-tti-saving-loading" title="Link to this heading"></a></h3>
<p>A Tenstorrent Image (TTI) is a standalone archive file that captures the entire compiled state of a
model. The contents of the archive include device configuration, compiler configuration, compiled model artifacts,
backend build files (e.g. overlay and risc binaries), model parameter tensors. There can be multiple advantages
with leveraging the usage of a TTI archive:</p>
<ol class="arabic simple">
<li><p>Offline target compilation of models on arbitrary device targets (i.e. target device does not have to be present/available on the machine to compile and save a TTI).</p></li>
<li><p>Loading a TTI archive allows the user to skip any long front-end and backend compilations of models onto the device
and directly begin executing the graph/module that was packaged in the *.tti after pushing inputs to queues.</p></li>
<li><p>TTI archives can be shared and loaded across different machines and environments.</p></li>
<li><p>When we save a TTI archive, we can configure the serialization format for the model parameters. This can be useful for
scenarios where the user wants to save the model parameters in a tilized-binary format to avoid tilizing during model inference.
By default the serialization format is pickle. To configure for alternate serialization formats, the user can set either:
PYBUDA_TTI_BACKEND_FORMAT=1 or PYBUDA_TTI_BACKEND_TILIZED_FORMAT=1 environment variables.</p></li>
</ol>
<p>For example, from a machine without a silicon device, we can save a TTI archive intended to be deployed on a silicon device.
We need to configure the device type and architecture of the target device and compile the model to a TTI archive.
This can be done by invoking the compile_to_image method on  <a class="reference internal" href="api.html#pybuda.TTDevice"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">TTDevice</span></code></span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span>
  <span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Wormhole_B0</span><span class="p">,</span>
  <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Silicon</span>
<span class="p">)</span>
<span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">device_img</span><span class="p">:</span> <span class="n">TTDeviceImage</span> <span class="o">=</span> <span class="n">tt0</span><span class="o">.</span><span class="n">compile_to_image</span><span class="p">(</span>
    <span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span>
    <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>This will create the archive file device_images/tt0.tti. The contents of a TTI file will contain:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/unzipped_tti_directory
├── device.json # Device state and compiled model metadata
├── &lt;module-name&gt;.yaml # netlist yaml
├── compile_and_runtime_config.json # compiler and runtime configurations
├── backend_build_binaries # backend build binaries
│   ├── device_desc.yaml
│   ├── cluster_desc.yaml
│   ├── brisc
│   ├── erisc
│   ├── nrisc
│   ├── hlks
│   ├── epoch_programs
├── tensors # directory containing serialized tensors
├── module_files # Python file containing the PybudaModule of the model
</pre></div>
</div>
<p>To load the TTI archive and inspect the contents:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device_img</span><span class="p">:</span> <span class="n">TTDeviceImage</span> <span class="o">=</span> <span class="n">TTDeviceImage</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">TTDeviceImage&lt;pybuda.TTDeviceImage&gt;::info()</span></code> method provides a summary of contents of the TTI:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device_img</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">Image Info...</span>
<span class="l l-Scalar l-Scalar-Plain">- Version Info</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pybuda_version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1.220624+dev.f63c9d32</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pybuda_commit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">7def2987</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">buda_backend_commit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">f2fd0fa3</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">Device Name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tt0</span>

<span class="l l-Scalar l-Scalar-Plain">Device Info...</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">arch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BackendDevice.Grayskull</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">chip_ids</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">backend device type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BackendType.Silicon</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">grid size</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">10</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">12</span><span class="p p-Indicator">]</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">harvested rows</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span>

<span class="l l-Scalar l-Scalar-Plain">Compilation Graph State...</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">training</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">ordered input shapes</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[[</span><span class="nv">1</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">],</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">]]</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">ordered targets shapes</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
</pre></div>
</div>
<p>We can now configure <a class="reference internal" href="api.html#pybuda.TTDevice"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">TTDevice</span></code></span></a> by using our image object and execute directly on device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">TTDeviceImage</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">TTDevice</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="n">img</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">img</span><span class="o">.</span><span class="n">get_input_shapes</span><span class="p">()]</span> <span class="c1"># create tensors using shape info from img</span>
<span class="n">device</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="c1"># push newly created input activation tensors to device</span>
<span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="create-tti-targeting-supported-silicon-devices">
<h3>Create TTI: Targeting Supported Silicon Devices<a class="headerlink" href="#create-tti-targeting-supported-silicon-devices" title="Link to this heading"></a></h3>
<p>In the example above, we saved a TTI file targeting a silicon device with default configuration (unharvested). There
are also convenience labels available that can be used to target specific silicon devices in our supported product spec.
The current support available is: {gs_e150, gs_e300, wh_n150, wh_n300}.</p>
<p>To target a specific silicon device, we can set the device type and architecture using <a class="reference internal" href="api.html#pybuda.set_configuration_options"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">set_configuration_options</span></code></span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span><span class="n">device_config</span><span class="o">=</span><span class="s2">&quot;wh_n150&quot;</span><span class="p">)</span>

<span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span>
  <span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Wormhole_B0</span><span class="p">,</span>
  <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Silicon</span>
<span class="p">)</span>
<span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">device_img</span><span class="p">:</span> <span class="n">TTDeviceImage</span> <span class="o">=</span> <span class="n">tt0</span><span class="o">.</span><span class="n">compile_to_image</span><span class="p">(</span>
    <span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span>
    <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="create-tti-targeting-custom-row-harvested-silicon-devices">
<h3>Create TTI: Targeting Custom Row-Harvested Silicon Devices<a class="headerlink" href="#create-tti-targeting-custom-row-harvested-silicon-devices" title="Link to this heading"></a></h3>
<p>We can also save a TTI file targeting a machine with silicon devices with harvested rows offline.
The only difference from the above is we need to manually induce the harvested rows before saving TTI.</p>
<p>We can set the harvested rows by invoking  <a class="reference internal" href="api.html#pybuda.set_configuration_options"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">set_configuration_options</span></code></span></a> with harvested_rows argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span><span class="n">harvested_rows</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">])</span> <span class="c1">#manually harvest row 1 and 11</span>

<span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span><span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Grayskull</span><span class="p">,</span> <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Silicon</span><span class="p">)</span>
<span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">device_img</span><span class="p">:</span> <span class="n">TTDeviceImage</span> <span class="o">=</span> <span class="n">tt0</span><span class="o">.</span><span class="n">compile_to_image</span><span class="p">(</span>
    <span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span>
    <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The code snippet creates the TTI file targeting silicon devices with row 1 and 11 harvested.
Accordingly, part of the TTI file slightly changes as well:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">Device Info...</span>
<span class="l l-Scalar l-Scalar-Plain">- arch</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BackendDevice.Grayskull</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">chip_ids</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">backend device type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BackendType.Silicon</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">grid size</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">8</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">12</span><span class="p p-Indicator">]</span><span class="w">    </span><span class="c1"># 2 rows are harvested from 10 rows</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">harvested rows</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2050</span><span class="w">  </span><span class="c1"># indicates row 1 and 11 are harvested (in binary, 100000000010)</span>
</pre></div>
</div>
<p>Note that only rows 1-5 and 7-11 are harvestable, and TTI loading will raise an error if the manually harvested rows in TTI does not match with that of the loaded silicon device.</p>
</section>
<section id="create-tti-targeting-custom-device-descriptor">
<h3>Create TTI: Targeting Custom Device Descriptor<a class="headerlink" href="#create-tti-targeting-custom-device-descriptor" title="Link to this heading"></a></h3>
<p>We can also save a TTI file targeting a machine with silicon devices with custom device descriptor (specified with file-path).
This can be done by setting the device descriptor using <a class="reference internal" href="api.html#pybuda.set_configuration_options"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">set_configuration_options</span></code></span></a> with backend_device_descriptor_path argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span><span class="n">backend_device_descriptor_path</span><span class="o">=</span><span class="s2">&quot;&lt;device-descriptor-path&gt;/wormhole_b0_4x6.yaml&quot;</span><span class="p">)</span>

<span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span><span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Wormhole_B0</span><span class="p">,</span> <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Silicon</span><span class="p">)</span>
<span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">device_img</span><span class="p">:</span> <span class="n">TTDeviceImage</span> <span class="o">=</span> <span class="n">tt0</span><span class="o">.</span><span class="n">compile_to_image</span><span class="p">(</span>
    <span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/tt0.tti&quot;</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span>
    <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The device-descriptor used during the offline compilation process will be embedded in the TTI-archive.
This device-descriptor will be used to configure the device during the TTI-loading process.</p>
</section>
<section id="embedded-tti-loading">
<h3>Embedded TTI Loading<a class="headerlink" href="#embedded-tti-loading" title="Link to this heading"></a></h3>
<p>Here’s an example of loading a generic TTI model from C++ for environments that do not have a packaged Python interpreter.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;memory&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;experimental/filesystem&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tt_backend.hpp&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tt_backend_api.hpp&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tt_backend_api_types.hpp&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;io_utils.h&quot;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">fs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">std</span><span class="o">::</span><span class="nn">experimental</span><span class="o">::</span><span class="nn">filesystem</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;TTI path not specified on the command line&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;Incorrect number of arguments specified to inference harness. Supported args: TTI_PATH NUM_INFERENCE_LOOPS&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Define path to pre-compiled model and output artifacts</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">output_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;tt_build/test_standalone_runtime&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">fs</span><span class="o">::</span><span class="n">create_directories</span><span class="p">(</span><span class="n">output_path</span><span class="p">);</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">inference_loops</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">model_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span><span class="w">  </span><span class="c1">// eg. &quot;/home_mnt/software/spatial2/backend/binaries/CI_TTI_TEST_BINARIES_WH/bert.tti&quot;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inference_loops</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">stoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Create a pre-compiled model object and a backend object from it using default config</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">tt</span><span class="o">::</span><span class="n">tt_device_image</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">tt</span><span class="o">::</span><span class="n">tt_device_image</span><span class="o">&gt;</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span><span class="w"> </span><span class="n">output_path</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">tt_backend</span><span class="o">&gt;</span><span class="w"> </span><span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt_backend</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_backend_config</span><span class="p">{});</span>

<span class="w">    </span><span class="c1">// The following code are organized into &lt;runtime process&gt; and &lt;io process&gt; sections</span>
<span class="w">    </span><span class="c1">// where the two processes can be running on different user spaces (e.g. host and soc)</span>

<span class="w">    </span><span class="c1">// &lt;runtime process&gt; - Initialize the backend</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">backend</span><span class="o">-&gt;</span><span class="n">initialize</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;Failed to initialize device&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// The following code must execute between initialize() and finish()</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inference_loops</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// &lt;io process&gt; - Push a microbatch of inputs to device</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">get_graph_input_names</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_dram_io_desc</span><span class="w"> </span><span class="n">io_desc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">io</span><span class="o">::</span><span class="n">utils</span><span class="o">::</span><span class="n">get_queue_descriptor</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">);</span>
<span class="w">            </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_PytorchTensorDesc</span><span class="w"> </span><span class="n">tensor_desc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">io</span><span class="o">::</span><span class="n">utils</span><span class="o">::</span><span class="n">get_tensor_descriptor</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">io_desc</span><span class="p">);</span>
<span class="w">            </span><span class="c1">// Fill the tensor descriptor with data. We choose to allocate dummy memory using the TT backend for this tensor.</span>
<span class="w">            </span><span class="c1">// The user is free to use previously allocated memory, or use the backend to allocate memory that is then filled with actual data.</span>
<span class="w">            </span><span class="n">tt</span><span class="o">::</span><span class="n">io</span><span class="o">::</span><span class="n">utils</span><span class="o">::</span><span class="n">fill_tensor_with_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_desc</span><span class="p">);</span>
<span class="w">            </span><span class="c1">// DMA the input tensor from host to device</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">tt</span><span class="o">::</span><span class="n">backend</span><span class="o">::</span><span class="n">push_input</span><span class="p">(</span><span class="n">io_desc</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_desc</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>
<span class="w">            </span><span class="c1">// Optional: Host memory management</span>
<span class="w">            </span><span class="c1">// - free releases storage on host (tensor data freed), since host is done with pushing data for this activation</span>
<span class="w">            </span><span class="c1">// - The user can choose not to free this memory and use it even after the data is in device DRAM</span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Pushed Input tensor &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; data ptr: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor_desc</span><span class="p">.</span><span class="n">ptr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">tt</span><span class="o">::</span><span class="n">backend</span><span class="o">::</span><span class="n">free_tensor</span><span class="p">(</span><span class="n">tensor_desc</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// &lt;runtime process&gt; - Run inference program, p_loop_count is the number of microbatches executed</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="w"> </span><span class="n">program_parameters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{{</span><span class="s">&quot;$p_loop_count&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;1&quot;</span><span class="p">}};</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">prog_name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">backend</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">get_programs</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">backend</span><span class="o">-&gt;</span><span class="n">run_program</span><span class="p">(</span><span class="n">prog_name</span><span class="p">,</span><span class="w"> </span><span class="n">program_parameters</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// &lt;io process&gt; - Pop a microbatch of outputs from device</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">get_graph_output_names</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_dram_io_desc</span><span class="w"> </span><span class="n">io_desc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">io</span><span class="o">::</span><span class="n">utils</span><span class="o">::</span><span class="n">get_queue_descriptor</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">);</span>
<span class="w">            </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_PytorchTensorDesc</span><span class="w"> </span><span class="n">tensor_desc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{};</span><span class="w">  </span><span class="c1">// passed into get_tensor below to be populated</span>

<span class="w">            </span><span class="c1">// DMA the output tensor from device to host</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">tt</span><span class="o">::</span><span class="n">backend</span><span class="o">::</span><span class="n">get_output</span><span class="p">(</span><span class="n">io_desc</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_desc</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Device memory management</span>
<span class="w">            </span><span class="c1">// - pop releases storage on device (queue entries popped), device can push more outputs to queue</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">tt</span><span class="o">::</span><span class="n">backend</span><span class="o">::</span><span class="n">pop_output</span><span class="p">(</span><span class="n">io_desc</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Host memory management</span>
<span class="w">            </span><span class="c1">// - free releases storage on host (tensor data freed), host is done with the output data</span>
<span class="w">            </span><span class="c1">// - The user can choose not to free this memory and use it for downstream tasks</span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Got Output tensor &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; data ptr: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor_desc</span><span class="p">.</span><span class="n">ptr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">            </span><span class="n">assert</span><span class="p">(</span><span class="n">tt</span><span class="o">::</span><span class="n">backend</span><span class="o">::</span><span class="n">free_tensor</span><span class="p">(</span><span class="n">tensor_desc</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// &lt;runtime process&gt; - Teardown the backend</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">backend</span><span class="o">-&gt;</span><span class="n">finish</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">DEVICE_STATUS_CODE</span><span class="o">::</span><span class="n">Success</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;Failed to shutdown device&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="pybuda-automatic-mixed-precision">
<h2>Pybuda Automatic Mixed Precision<a class="headerlink" href="#pybuda-automatic-mixed-precision" title="Link to this heading"></a></h2>
<section id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h3>
<p>Automatic Mixed Precision (AMP) is a technique employed by Pybuda to leverage the hardware’s ability to adjust precision along the hardware data path.
This technique mixes native support for low-precision block floating point (BFP) data format with higher precision data-formats (float16, bfloat16)
to achieve accuracy results close or at parity relative to half precision.</p>
<p>There are several benefits enabling AMP:</p>
<ul class="simple">
<li><p>The ability make a trade at runtime between accuracy vs. performance based on application requirements.</p></li>
<li><p>The ability to speed up compute-bound operations like matrix multiplication by reducing the cycles required.</p></li>
<li><p>The ability to speed up memory-bound operations by reducing memory traffic between DRAM&lt;-&gt;tensix or tensix&lt;-&gt;tensix via on-chip interconnect.</p></li>
<li><p>The ability to use half-precision/single-precision weights and run them in mixed precision without any changes to the model.</p></li>
</ul>
<p>For additional details about our support for data formats, refer to <a class="reference internal" href="dataformats.html#data-formats"><span class="std std-ref">Data Formats</span></a>. For additional details about Math Fidelity, refer to <a class="reference internal" href="dataformats.html#math-fidelity"><span class="std std-ref">Math Fidelity</span></a></p>
</section>
<section id="automatic-mixed-precision-amp">
<h3>Automatic Mixed Precision (AMP)<a class="headerlink" href="#automatic-mixed-precision-amp" title="Link to this heading"></a></h3>
<p>During model compilation, the user will set the default configuration for precision and Math Fidelity of the model. This can be configured through the <a class="reference internal" href="api.html#pybuda.set_configuration_options"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">pybuda.set_configuration_options</span></code></span></a> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s begin by setting the default single-precision configuration for the model:</span>
<span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span>
    <span class="n">default_df_override</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16_b</span><span class="p">,</span>
    <span class="n">accumulate_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16_b</span><span class="p">,</span>
    <span class="n">math_fidelity</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">MathFidelity</span><span class="o">.</span><span class="n">HiFi3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>AMP uses the global configuration set by the user and additionally enables a set of heuristics to determine the best precision for each operator in the model. These heuristics are based on empirical accuracy results. There are various switches uses to control the heuristics employed tune how aggressive these heuristics are. These switches are enabled by setting the following environment variables:</p>
<ul class="simple">
<li><p>PYBUDA_AMP_LIGHT=0: Disabled. No mixed precision settings are applied and the global configuration is used. The default MathFidelity is used for all operations.</p></li>
<li><p>PYBUDA_AMP_LIGHT=1: Set the weights and bias inputs of MatMul operations to BFP8A/BFP8B and MathFidelity.HiFi2. For all other operations, the default MathFidelity provided by the user is used.</p></li>
<li><p>PYBUDA_AMP_LIGHT=2: Set the weights and bias inputs of MatMul operations to BFP4A/BFP4B and MathFidelity.LoFi. For all other operations, the default MathFidelity provided by the user is used.</p></li>
</ul>
<p>We also offer a switch to employ more aggressive mixed precision settings on select operators:</p>
<ul class="simple">
<li><p>PYBUDA_AMP_LEVEL=1: Set layernorm, softmax and fused operators to bfloat16 while keeping the rest of the model at BFP8B. For MatMul operations, HiFi2 is used, and for all other operations, the default MathFidelity provided by the user is used.</p></li>
</ul>
</section>
<section id="user-defined-mixed-precision-configurations">
<h3>User-Defined Mixed Precision Configurations<a class="headerlink" href="#user-defined-mixed-precision-configurations" title="Link to this heading"></a></h3>
<p>With a recognition that precision tuning may differ across models, Pybuda provides an API for fine-grained control over the precision of arbitrary inputs, parameters and operators in the graph through: <code class="docutils literal notranslate"><span class="pre">pybuda.config.configure_mixed_precision</span></code>.</p>
<p>Here’s a simple example for adjusting the precision of select operators, inputs and parameters in the model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pybuda</span>

<span class="c1"># Let&#39;s target matmul operators and set the accumulation data-format to bfloat16, output data-format to BFP8_b and math fidelity to HiFi2.</span>
<span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">configure_mixed_precision</span><span class="p">(</span>
 <span class="n">op_type</span><span class="o">=</span><span class="s2">&quot;matmul&quot;</span><span class="p">,</span>
 <span class="n">math_fidelity</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">MathFidelity</span><span class="o">.</span><span class="n">HiFi2</span><span class="p">,</span>
 <span class="n">accumulate_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16_b</span><span class="p">,</span>
 <span class="n">output_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Bfp8_b</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># We&#39;ll also target the KQV matmul weights for attention modules and set them to lower precision</span>
<span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">configure_mixed_precision</span><span class="p">(</span>
 <span class="n">name_regex</span><span class="o">=</span><span class="s2">&quot;layer.*.attention.self.(query|value|key).weight&quot;</span><span class="p">,</span>
 <span class="n">output_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Bfp8_b</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># We&#39;ll also target the attention mask to set the data-format to BFP2_b.</span>
<span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">configure_mixed_precision</span><span class="p">(</span>
 <span class="n">name_regex</span><span class="o">=</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
 <span class="n">output_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Bfp2_b</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="user-defined-intermediate-queues">
<h3>User-Defined Intermediate Queues<a class="headerlink" href="#user-defined-intermediate-queues" title="Link to this heading"></a></h3>
<p>Pybuda supports the ability to inspect/collect intermediate tensors at runtime to aid in the debug and model analysis of mixed precision configurations.
This enables a user to tag operations of interest during graph compilation and dedicated intermediate queues will be created to checkpoint intermediates.</p>
<p>Here is a simple example to (1) tag operations of interest and (2) fetch intermediates from device.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pybuda</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PyBudaTestModule</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyBudaModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">matmul1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul1&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span><span class="p">)</span>
        <span class="n">matmul1_gelu</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gelu</span><span class="p">(</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span> <span class="n">matmul1</span><span class="p">)</span>
        <span class="n">matmul2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul2&quot;</span><span class="p">,</span> <span class="n">matmul1_gelu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">matmul2</span>

<span class="c1"># Configure Pybuda compilation options to include a list of operations to collect intermediate tensors</span>
<span class="n">tagged_operations</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;matmul1&quot;</span><span class="p">,</span> <span class="s2">&quot;gelu&quot;</span><span class="p">]</span>
<span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span><span class="n">op_intermediates_to_save</span><span class="o">=</span><span class="n">tagged_operations</span><span class="p">)</span>

<span class="c1"># Invoke the run_inference API to create device, compile and run module on device:</span>
<span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;test_module&quot;</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)])</span>

<span class="c1"># After running inference, the intermediates queue will contain the ordered list of tagged intermediates</span>
<span class="n">intermediates_queue</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">get_intermediates_queue</span><span class="p">()</span>
<span class="n">matmul1_tensor</span><span class="p">,</span> <span class="n">gelu_tensor</span> <span class="o">=</span> <span class="n">intermediates_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

<span class="c1"># Print tensor values recorded from device inference</span>
<span class="nb">print</span><span class="p">(</span><span class="n">matmul1_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gelu_tensor</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="multiple-devices">
<h2>Multiple Devices<a class="headerlink" href="#multiple-devices" title="Link to this heading"></a></h2>
<section id="using-multiple-tenstorrent-devices">
<h3>Using Multiple Tenstorrent Devices<a class="headerlink" href="#using-multiple-tenstorrent-devices" title="Link to this heading"></a></h3>
<p>PyBuda makes it easy to parallelize workloads onto multiple devices. A single <a class="reference internal" href="api.html#pybuda.TTDevice"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">TTDevice</span></code></span></a> can be used as a wrapper to any number of available
Tenstorrent devices accessible to the host - either locally or through ethernet. The PyBuda compiler will then break up the workload over
assigned devices using either pipeline or model parllelism strategies, or a combination of both.</p>
<p>The easiest way to use all available hardware is to set <code class="docutils literal notranslate"><span class="pre">num_chips</span></code> parameter in <a class="reference internal" href="api.html#pybuda.TTDevice"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">TTDevice</span></code></span></a> to 0, which instructs it to auto-detect and use everything it can find.
However, <code class="docutils literal notranslate"><span class="pre">num_chips</span></code> and <code class="docutils literal notranslate"><span class="pre">chip_ids</span></code> parameters can be used to select a subset of available hardware:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span> <span class="o">=</span> <span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">num_chips</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># Take first 3 available chips</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt0</span> <span class="o">=</span> <span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">chip_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="c1"># Skip chip id 1 and take 3 chips</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="api.html#pybuda.TTDevice"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">TTDevice</span></code></span></a> for more details.</p>
</section>
</section>
<section id="pybuda-multi-model-support-embedded-applications-only">
<h2>Pybuda Multi-Model Support (Embedded Applications Only)<a class="headerlink" href="#pybuda-multi-model-support-embedded-applications-only" title="Link to this heading"></a></h2>
<section id="id1">
<h3>Introduction<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p>PyBuda allows users to merge several models into a single Tenstorrent Device Image, with minimal workflow overhead. The TTI can then be consumed by the C++ Backend and run on a Tenstorrent Device.</p>
<p>A typical process to generate and execute a Multi-Model workload is as follows:</p>
<p><strong>Compilation: Either Offline or on a Tenstorrent Device</strong></p>
<ol class="arabic simple">
<li><p>Generate TTIs for each model in the workload.</p></li>
<li><p>Run the Model-Merging tool to consolidate all models into a single TTI.</p></li>
</ol>
<p><strong>Execution: On a Tenstorrent Device</strong></p>
<ol class="arabic simple">
<li><p>Spawn an application using the C++ backend APIs to deploy the workload contained in the TTI. An example application is provided in the Embedded TTI Loading section.</p></li>
</ol>
<p>Fusing multiple independent models is well tested with several State of the Art models (including ViT, Mobilenet, ResNet50 …). Supporting pipelined models is currently under active development.</p>
<p>Below, we describe the APIs and associated tools used to fuse models without any dependencies.</p>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h3>
<p>Pybuda exposes two entry points for users to run the Model Merging Tool:</p>
<ol class="arabic simple">
<li><p>Command Line Interface to specify the list of models to merge along with optional arguments. These include parameters enabling/disabling certain optimizations.</p></li>
<li><p>Python API to be consumed by user applications. Usage of this API is very similar to the Command Line Tool.</p></li>
</ol>
<p><strong>Command Line Interface</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>pybuda/pybuda/tools/tti_merge.py<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>-mbl<span class="w"> </span><span class="o">{</span>dirname<span class="o">}]</span>
<span class="w">  </span><span class="o">[</span>-mdl<span class="w"> </span><span class="o">{</span>models<span class="o">}]</span><span class="w"> </span><span class="o">[</span>-a<span class="w"> </span><span class="o">{</span>arch<span class="o">}]</span>
<span class="w">  </span><span class="o">[</span>-mml<span class="w"> </span><span class="o">{</span>filename<span class="o">}]</span><span class="w"> </span><span class="o">[</span>-scr<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-dqo<span class="o">]</span>
</pre></div>
</div>
<p>The following arguments are available when using tti_merge.py</p>
<section id="table-1-tt-smi-optional-arguments">
<h4>Table 1. TT-SMI optional arguments.<a class="headerlink" href="#table-1-tt-smi-optional-arguments" title="Link to this heading"></a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Function</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-h, –help</p></td>
<td><p>Show help message and exit</p></td>
</tr>
<tr class="row-odd"><td><p>-mbl, –model_binaries_location</p></td>
<td><p>Relative path to where model TTIs are stored [Required]</p></td>
</tr>
<tr class="row-even"><td><p>-mdl, –models</p></td>
<td><p>List of models to be merged (names must match TTI filenames) [Required]</p></td>
</tr>
<tr class="row-odd"><td><p>-a, –arch</p></td>
<td><p>Target Tenstorrent Architecture (default = wormhole_b0) [Optional]</p></td>
</tr>
<tr class="row-even"><td><p>-mml, –merged_model_location</p></td>
<td><p>Relative path to where the Multi-Model TTI will be emitted (default = merged_model.tti) [Optional]</p></td>
</tr>
<tr class="row-odd"><td><p>-scr, –skip_channel_reallocation</p></td>
<td><p>Disable memory optimization that switches channels for queues when OOM during memory allocation (default = False) [Optional]</p></td>
</tr>
<tr class="row-even"><td><p>-dqo, –dynamic_queue_overlap_off</p></td>
<td><p>Disable memory optimization allowing dynamic queues to overlap in memory channels (default = False) [Optional]</p></td>
</tr>
</tbody>
</table>
<p>As an example, given the following directory structure in the Pybuda root directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>device_images_to_merge/
├--<span class="w"> </span>bert_large.tti
├--<span class="w"> </span>deit.tti
├--<span class="w"> </span>hrnet.tti
├--<span class="w"> </span>inception.tti
├--<span class="w"> </span>mobilenet_v1.tti
├--<span class="w"> </span>mobilenet_v2.tti
├--<span class="w"> </span>mobilenet_v3.tti
├--<span class="w"> </span>resnet.tti
├--<span class="w"> </span>unet.tti
├--<span class="w"> </span>vit.tti
</pre></div>
</div>
<p>The following command will generate a Multi-Model TTI (with memory optimizations enabled) and store it in multi_model_workload.tti:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>pybuda/pybuda/tools/tti_merge.py<span class="w"> </span>-mbl<span class="w"> </span>device_images_to_merge/<span class="w"> </span>-mdl<span class="w"> </span>bert_large<span class="w"> </span>deit<span class="w"> </span>hrnet<span class="w"> </span>inception<span class="w"> </span>mobilenet_v1<span class="w"> </span>mobilenet_v2<span class="w"> </span>mobilenet_v3<span class="w"> </span>resnet<span class="w"> </span>unet<span class="w"> </span>vit<span class="w"> </span>-mml<span class="w"> </span>multi_model_workload.tti
</pre></div>
</div>
<p><strong>Python API</strong></p>
<p>This API provides identical functionality as the command line interface, for cases where the Model Merging step needs to be automated.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># API Declaration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">merge_models</span><span class="p">(</span><span class="n">model_bin_location</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">arch</span> <span class="o">=</span> <span class="s2">&quot;wormhole_b0&quot;</span><span class="p">,</span> <span class="n">merged_model_location</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">switch_chans_if_capacity_hit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">overlap_dynamic_queues</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Here the arguments switch_chans_if_capacity_hit and overlap_dynamic_queues corresponds to memory optimizations, which are enabled my default.</p>
<p>The following Python code generates a Multi-Model TTI in a manner identical to the command listed in the previous section:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pybuda.tools.tti_merge</span><span class="w"> </span><span class="kn">import</span> <span class="n">merge_models</span>

<span class="n">model_binary_loc</span> <span class="o">=</span> <span class="s2">&quot;device_images_to_merge&quot;</span>
<span class="n">models_to_merge</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;bert_large&quot;</span><span class="p">,</span> <span class="s2">&quot;deit&quot;</span><span class="p">,</span> <span class="s2">&quot;hrnet&quot;</span><span class="p">,</span> <span class="s2">&quot;inception&quot;</span><span class="p">,</span> <span class="s2">&quot;mobilenet_v1&quot;</span><span class="p">,</span> <span class="s2">&quot;mobilenet_v2&quot;</span><span class="p">,</span> <span class="s2">&quot;mobilenet_v3&quot;</span><span class="p">,</span> <span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="s2">&quot;unet&quot;</span><span class="p">,</span> <span class="s2">&quot;vit&quot;</span><span class="p">]</span>
<span class="n">target_arch</span> <span class="o">=</span> <span class="s2">&quot;wormhole_b0</span>
<span class="n">merged_model_location</span> <span class="o">=</span> <span class="s2">&quot;multi_model_workload.tti&quot;</span>

<span class="c1"># Individual Model Generation Code Goes Here</span>

<span class="n">merge_models</span><span class="p">(</span><span class="n">model_binary_loc</span><span class="p">,</span> <span class="n">models_to_merge</span><span class="p">,</span> <span class="n">target_arch</span><span class="p">,</span> <span class="n">merged_model_location</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Memory Profiler</strong></p>
<p>During the model fusion process, the API presented above is responsible for performing memory reallocation. Users may be interested in the memory footprint of the fused model (both Device and Host DRAM).</p>
<p>To fullfil this requirement, the tool reports memory utilization post reallocation. An example using a model compiled for Wormhole (with 6 Device and upto 4 Host DRAM channels) is provided below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>Displaying memory footprint per DRAM channel (MB):
0 : 161.17
1 : 511.12
2 : 577.51
3 : 200.27
4 : 204.41
5 : 339.57
Displaying memory footprint per Host channel (MB):
0 : 132.88
1 : 0.0
2 : 0.0
3 : 0.0</p>
</section>
</section>
</section>
<section id="tt-smi">
<h2>TT-SMI<a class="headerlink" href="#tt-smi" title="Link to this heading"></a></h2>
<section id="tt-smi-introduction">
<h3>TT-SMI Introduction<a class="headerlink" href="#tt-smi-introduction" title="Link to this heading"></a></h3>
<p>TT-SMI is a command-line utility for monitoring and retrieving information about Tenstorrent devices. It provides two operating modes:</p>
<ol class="arabic simple">
<li><p><strong>Live Display</strong>. Visualize live telemetry data, check on host info and device info.</p></li>
<li><p><strong>CLI</strong>. Save a snapshot of telemetry into a .log file, dump telemetry into .csv/.xlsx, and perform warm resets on devices.</p></li>
</ol>
</section>
<section id="id2">
<h3>Usage<a class="headerlink" href="#id2" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tt-smi<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>-v<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-t<span class="w"> </span><span class="o">{</span>default,dark<span class="o">}]</span><span class="w"> </span><span class="o">[</span>-nc<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-i<span class="w"> </span><span class="o">[</span>seconds<span class="o">]]</span><span class="w"> </span><span class="o">[</span>-s<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-f<span class="w"> </span><span class="o">[</span>filename<span class="o">]]</span><span class="w"> </span><span class="o">[</span>-d<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-dir<span class="w"> </span><span class="o">[</span>dirname<span class="o">]]</span>
<span class="w">  </span><span class="o">[</span>-dur<span class="w"> </span>seconds<span class="o">]</span><span class="w"> </span><span class="o">[</span>-wr<span class="o">]</span>
<span class="w">  </span><span class="o">[</span>-mr<span class="o">]</span><span class="w"> </span><span class="o">[</span>--external<span class="o">]</span>
</pre></div>
</div>
<p>The following optional arguments are available when calling TT-SMI:</p>
<section id="id3">
<h4>Table 1. TT-SMI optional arguments.<a class="headerlink" href="#id3" title="Link to this heading"></a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Function</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-h, –help</p></td>
<td><p>Show help message and exit</p></td>
</tr>
<tr class="row-odd"><td><p>-v, –version</p></td>
<td><p>Show program’s version number and exit</p></td>
</tr>
<tr class="row-even"><td><p>-t {default, dark}, –theme {default, dark}</p></td>
<td><p>Change color theme of live display. Use dark theme for light backgrounds</p></td>
</tr>
<tr class="row-odd"><td><p>-nc, –no-color</p></td>
<td><p>Remove color from output</p></td>
</tr>
<tr class="row-even"><td><p>-i [seconds], –interval [seconds]</p></td>
<td><p>Change time interval between readings. Default: 0.5s</p></td>
</tr>
<tr class="row-odd"><td><p>-s, –snapshot</p></td>
<td><p>Take snapshot of current host and device information</p></td>
</tr>
<tr class="row-even"><td><p>-f [filename], –filename [filename]</p></td>
<td><p>Change filename for snapshot. Default: tt-smi-snapshot_<timestamp></p></td>
</tr>
<tr class="row-odd"><td><p>-d, –dump</p></td>
<td><p>Dump device telemetry to file</p></td>
</tr>
<tr class="row-even"><td><p>-dir [dirname], –dump_dir [dirname]</p></td>
<td><p>Change directory path to dump to. Default: tt-smi-dump_<timestamp>/</p></td>
</tr>
<tr class="row-odd"><td><p>-dur [seconds], –duration [seconds]</p></td>
<td><p>Set duration in seconds to dump for</p></td>
</tr>
<tr class="row-even"><td><p>-wr, –warm_reset</p></td>
<td><p>Warm reset board</p></td>
</tr>
<tr class="row-odd"><td><p>-mr, –mobo_nb_reset</p></td>
<td><p>Warm reset mobo</p></td>
</tr>
<tr class="row-even"><td><p>–external</p></td>
<td><p>Run external version of TT-SMI</p></td>
</tr>
</tbody>
</table>
<p>Some usage examples include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span></code> (run live display)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-t</span> <span class="pre">dark</span></code> (run live display with dark theme)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-nc</span></code> (run live display with no color)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-i</span> <span class="pre">0.01</span></code> (run live display with interval between readings set to 0.01s)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-s</span></code> (save snapshot to ./tt-smi-logs/tt-smi-snapshot_<timestamp>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-s</span> <span class="pre">-f</span> <span class="pre">my\_file.log</span></code> (save snapshot to ./my_file.log)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-d</span></code> (dump until Enter is pressed and save to ./tt-smi-logs/tt-smi-dump_<timestamp>/)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-d</span> <span class="pre">-dir</span> <span class="pre">my\_dir</span></code> (dump until Enter is pressed and save in ./my_dir/)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-d</span> <span class="pre">-dur</span> <span class="pre">30</span></code> (dump for 30 seconds and save to ./tt-smi-logs/tt-smi-dump_<timestamp>/)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-d</span> <span class="pre">-dir</span> <span class="pre">my\_dir</span> <span class="pre">-dur</span> <span class="pre">30</span></code> (dump for 30 seconds and save in ./my_dir/)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-wr</span></code> (warm reset the board)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tt-smi</span> <span class="pre">-mr</span></code> (warm reset mobo)</p></li>
</ul>
</section>
</section>
<section id="live-display-mode">
<h3>Live Display Mode<a class="headerlink" href="#live-display-mode" title="Link to this heading"></a></h3>
<p>The live display mode of TT-SMI shows several content boxes by default: the header, host info, compatibility check, device info, and footer.</p>
<p>The header displays TT-SMI version, the title, and the current datetime. The Host Info box provides some specs about the host system running TT-SMI, while the Compatibility Check box shows if device status and host system requirements are currently being met. The footer shows an abbreviated list of keyboard shortcuts.</p>
<p>The following live display key presses astomize the view and perform quick actions:</p>
<section id="table-2-live-display-keyboard-shortcuts">
<h4>Table 2. Live display keyboard shortcuts<a class="headerlink" href="#table-2-live-display-keyboard-shortcuts" title="Link to this heading"></a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Action</p></th>
<th class="head"><p>Key Press</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Open device info tab</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Open device telemetry tab</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even"><td><p>Open device firmware tab</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-odd"><td><p>Toggle left sidebar</p></td>
<td><p>t</p></td>
</tr>
<tr class="row-even"><td><p>Toggle helper menu</p></td>
<td><p>h</p></td>
</tr>
<tr class="row-odd"><td><p>Toggle view of telemetry limits</p></td>
<td><p>w</p></td>
</tr>
<tr class="row-even"><td><p>Toggle view of telemetry average</p></td>
<td><p>v</p></td>
</tr>
<tr class="row-odd"><td><p>Take snapshot</p></td>
<td><p>s</p></td>
</tr>
<tr class="row-even"><td><p>Start/Stop telemetry dump</p></td>
<td><p>d</p></td>
</tr>
</tbody>
</table>
<p>The device info tab shows some board info, chip info, DRAM status, and PCIe link status.</p>
<p>The device telemetry tab displays the following values in real-time: core voltage, current, and power, clock frequencies, core temperature, voltage regulator (VREG) temperature, inlet temperature, and outlet temperatures. Several values have expected maximum limits, shown in yellow bold text.</p>
<p>The device firmware versions tab shows data about the firmware on each device.</p>
</section>
</section>
<section id="cli-mode">
<h3>CLI Mode<a class="headerlink" href="#cli-mode" title="Link to this heading"></a></h3>
</section>
<section id="dump-telemetry">
<h3>Dump Telemetry<a class="headerlink" href="#dump-telemetry" title="Link to this heading"></a></h3>
<p>To dump telemetry data for detected Tenstorrent devices to a spreadsheet format, use TT-SMI with the -d option. Unless a duration is specified with -dur, the telemetry dump will continue until the user presses Enter.</p>
<p>The resulting data is dumped into a .csv and an .xlsx file.</p>
<section id="table-3-telemetry-dump-output-for-one-chip-in-spreadsheet-format">
<h4>Table 3. Telemetry dump output for one chip in spreadsheet format<a class="headerlink" href="#table-3-telemetry-dump-output-for-one-chip-in-spreadsheet-format" title="Link to this heading"></a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Timestamp (s)</p></th>
<th class="head"><p>Core Voltage (V)</p></th>
<th class="head"><p>AICLK (MHz)</p></th>
<th class="head"><p>ARCCLK (MHz)</p></th>
<th class="head"><p>AXICLK (MHz)</p></th>
<th class="head"><p>Core Current (A)</p></th>
<th class="head"><p>Core Power (W)</p></th>
<th class="head"><p>Core Temp (°C)</p></th>
<th class="head"><p>VREG Temp (°C)</p></th>
<th class="head"><p>Inlet Temp (°C)</p></th>
<th class="head"><p>Outlet Temp 1 (°C)</p></th>
<th class="head"><p>Outlet Temp 2 (°C)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>0.502691</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>41</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>1.004782</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>40.8</p></td>
<td><p>42</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>1.506589</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>40.9</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>2.008529</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>40.9</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>2.510333</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>40.9</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>3.012129</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>37</p></td>
<td><p>40.8</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>3.513459</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>38</p></td>
<td><p>41.1</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>4.015265</strong></p></td>
<td><p>0.8</p></td>
<td><p>810</p></td>
<td><p>540</p></td>
<td><p>900</p></td>
<td><p>47</p></td>
<td><p>38</p></td>
<td><p>41</p></td>
<td><p>43</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="snapshot">
<h3>Snapshot<a class="headerlink" href="#snapshot" title="Link to this heading"></a></h3>
<p>Using TT-SMI with the -s option generates an output log file using telemetry and host data from a single moment in time.</p>
</section>
<section id="warm-reset">
<h3>Warm Reset<a class="headerlink" href="#warm-reset" title="Link to this heading"></a></h3>
<p>TT-SMI can be used with the -wr option to warm reset Tenstorrent devices (reset without rebooting the host system). Users can enter the indices of any devices and press Enter to reset them.</p>
</section>
<section id="warm-reset-mobo">
<h3>Warm Reset Mobo<a class="headerlink" href="#warm-reset-mobo" title="Link to this heading"></a></h3>
<p>With the -mr option, TT-SMI will warm reset the mobo. User will be prompt to enter the host name of the mobo and the ethernet port(s) connected on the mobo.</p>
</section>
</section>
<section id="examples-of-pybuda-use-cases">
<h2>Examples of PyBuda use cases<a class="headerlink" href="#examples-of-pybuda-use-cases" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SPDX-FileCopyrightText: © 2024 Tenstorrent AI ULC</span>

<span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1">#</span>
<span class="c1"># Test &quot;user experience&quot; scenarios, i.e. different ways to use the API to run things on TT hardware</span>
<span class="c1"># Each test intentionally creates everything from scratch and uses no verification env, so that each</span>
<span class="c1"># of these tests can be used as user examples.</span>
<span class="c1"># There&#39;s also no verification of correctness of data, as that&#39;s not the point of these tests.</span>
<span class="c1">#</span>
<span class="c1"># All of these tests will run on silicon, in concurrent mode, by default. However, setting </span>
<span class="c1"># PYBUDA_DEVMODE=1 env variable will drop them into Golden+sequential mode.</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">queue</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pybuda</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pybuda.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">_get_global_compiler_config</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pybuda.schedulers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LearningRateScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pybuda.pybudaglobal</span><span class="w"> </span><span class="kn">import</span> <span class="n">pybuda_reset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pybuda._C.backend_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">BackendDevice</span><span class="p">,</span> <span class="n">BackendType</span><span class="p">,</span> <span class="n">DeviceMode</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">test.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">download_model</span>

<span class="c1"># https://github.com/pytorch/pytorch/wiki/Autograd-and-Fork</span>
<span class="n">mp_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s1">&#39;spawn&#39;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_safe_read</span><span class="p">(</span><span class="n">q</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read a queue, but return None if an error was raised in the meantime, preventing a hang on error.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span> <span class="k">as</span> <span class="n">_</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">error_raised</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Error raised in pybuda&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># Sample PyBuda module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PyBudaTestModule</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyBudaModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="n">act2</span><span class="p">):</span>
        <span class="n">m1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul1&quot;</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span><span class="p">)</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul2&quot;</span><span class="p">,</span> <span class="n">act2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m2</span>

<span class="c1"># Sample PyBuda module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PyBudaTestModuleOneOut</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyBudaModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="n">act2</span><span class="p">):</span>
        <span class="n">m1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul1&quot;</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span><span class="p">)</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="s2">&quot;matmul2&quot;</span><span class="p">,</span> <span class="n">act2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">m2</span>

<span class="c1"># Sample PyBuda module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PyBudaTestQueryKeyModule</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyBudaModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">key_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">):</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_query&quot;</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_weights</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">HSlice</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_query_slice&quot;</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>

        <span class="n">key</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_key&quot;</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">key_weights</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">HSlice</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_key_slice&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_key_transpose&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mha_as&quot;</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attention_scores</span>


<span class="k">class</span><span class="w"> </span><span class="nc">PyBudaTestForkWithThreeUsers</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyBudaModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mm_a_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mm_b_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mm_c_weights</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mm_a&quot;</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm_a_weights</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mm_b&quot;</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm_b_weights</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mm_c&quot;</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm_c_weights</span><span class="p">)</span>

        <span class="n">add_a_b</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;add_a_b&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">add_a_b_c</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;add_a_b_c&quot;</span><span class="p">,</span> <span class="n">add_a_b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">add_a_b_c</span>



<span class="c1"># Sample PyTorch module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PyTorchTestModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="n">act2</span><span class="p">):</span>
        <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">act1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span><span class="p">)</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">act2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m1</span>

<span class="c1"># Sample PyTorch module</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PyTorchTestModuleOneOut</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act1</span><span class="p">,</span> <span class="n">act2</span><span class="p">):</span>
        <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">act1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights1</span><span class="p">)</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">act2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">m2</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PyTorchTestModuleOneInputAndOneOut</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">m</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PyTorchLoss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1">#</span>
<span class="c1"># Run inference on module directly</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_module_direct_pybuda</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Run single inference pass on a PyBuda module directly</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_module_direct_pytorch</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Run single inference pass on a PyTorch module, using a wrapper to convert to PyBuda first</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;direct_pt&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">())</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Run inference through run_inference without placing on device</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_direct_pybuda</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Run inference on a PyBuda module, with given inputs</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;act2&quot;</span> <span class="p">:</span> <span class="n">input2</span><span class="p">,</span> <span class="s2">&quot;act1&quot;</span> <span class="p">:</span> <span class="n">input1</span><span class="p">}</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;run_direct&quot;</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">inputs</span><span class="p">])</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_direct_pytorch</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Run inference, using a wrapper to convert PyTorch module to PyBuda, and with given inputs</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;act2&quot;</span> <span class="p">:</span> <span class="n">input2</span><span class="p">,</span> <span class="s2">&quot;act1&quot;</span> <span class="p">:</span> <span class="n">input1</span><span class="p">}</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;run_direct_pt&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">inputs</span><span class="p">])</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>


<span class="c1">#</span>
<span class="c1"># Run inference by placing on device first</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_placed_pybuda</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Create a TT device</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>

    <span class="c1"># Place a module on the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;placed&quot;</span><span class="p">))</span>

    <span class="c1"># Push intputs to the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run pipeline, and read the outputs</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_placed_pytorch</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Create a TT device</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>

    <span class="c1"># Place a module on the device, using a wrapper to convert PyTorch module to PyBuda</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;placed_pt&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()))</span>
    
    <span class="c1"># Push intputs to the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run pipeline, and read the outputs</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Repeated calls to run inference on the same module</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_module_direct_repeated</span><span class="p">():</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;direct&quot;</span><span class="p">)</span>

    <span class="c1"># Run on given inputs</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># Run again, without recompiling</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># Run again, without recompiling</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_placed_repeated</span><span class="p">():</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;placed&quot;</span><span class="p">))</span>

    <span class="c1"># Push one input and run</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># Push two more inputs, and run one more time on both inputs, without recompiling</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">input_count</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>


<span class="c1">#</span>
<span class="c1"># Run inference through setup + run_forward calls</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_setup_forward_calls</span><span class="p">():</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;placed&quot;</span><span class="p">))</span>

    <span class="c1"># Compile &amp; initialize the pipeline for inference, with given shapes</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)))</span>
        
    <span class="c1"># Push &amp; run_forward manually</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">))</span>


<span class="c1">#</span>
<span class="c1"># Run inference in concurrent mode, then push more inputs afterwards (won&#39;t work on Golden)</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_run_inference_delayed_push</span><span class="p">():</span>
    
    <span class="c1">#### Skip the test on golden</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
    <span class="k">if</span> <span class="s2">&quot;PYBUDA_DEVMODE&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">()</span>
    <span class="c1">####</span>

    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;placed&quot;</span><span class="p">))</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run with input count 3, although only one is pushed</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">input_count</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Read one output that should&#39;ve been produced</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># The inference thread is running in the background, waiting for data. Let&#39;s push two more.</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Read two more outputs</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Run inference on multiple devices - combinations of cpu / tt device</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_cpu_tt_pipeline</span><span class="p">():</span>

    <span class="n">cpu0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu0&quot;</span><span class="p">)</span>
    <span class="n">cpu0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()))</span>
    <span class="n">tt1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt1&quot;</span><span class="p">)</span>
    <span class="n">tt1</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">))</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">cpu0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_cpu_tt_pipeline_compact</span><span class="p">():</span>

    <span class="n">cpu0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()))</span>
    <span class="n">tt1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">))</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">cpu0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">))</span>

<span class="c1"># Run training, read back checkpoints and loss</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_read_back</span><span class="p">():</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span>
            <span class="n">default_df_override</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16_b</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModuleOneOut</span><span class="p">(</span><span class="s2">&quot;module&quot;</span><span class="p">))</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="s2">&quot;l1_loss&quot;</span><span class="p">))</span>

    <span class="n">loss_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">checkpoint_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_training</span><span class="p">(</span><span class="n">checkpoint_queue</span> <span class="o">=</span> <span class="n">checkpoint_q</span><span class="p">,</span> <span class="n">loss_queue</span><span class="o">=</span><span class="n">loss_q</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;checkpoint: &quot;</span><span class="p">,</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">checkpoint_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loss: &quot;</span><span class="p">,</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">loss_q</span><span class="p">))</span>

<span class="c1"># Run training pipeline, with loss on CPU, read back checkpoints and loss</span>
<span class="c1">#@pytest.mark.skip(reason=&quot;Intermittent hangs on silicon&quot;)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_pipeline_read_back</span><span class="p">():</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()))</span>
    <span class="n">cpu1</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1loss&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>

    <span class="n">loss_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">checkpoint_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">cpu1</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_training</span><span class="p">(</span><span class="n">checkpoint_queue</span> <span class="o">=</span> <span class="n">checkpoint_q</span><span class="p">,</span> <span class="n">loss_queue</span><span class="o">=</span><span class="n">loss_q</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;checkpoint: &quot;</span><span class="p">,</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">checkpoint_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loss: &quot;</span><span class="p">,</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">loss_q</span><span class="p">))</span>


<span class="c1">#</span>
<span class="c1"># Run inference pipeline on a Transformers model</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_transformers_pipeline_inference</span><span class="p">():</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">BertTokenizer</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">(</span><span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">)</span>
    <span class="n">input_sentence</span> <span class="o">=</span> <span class="s2">&quot;BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was pretrained with two objectives: Masked language modeling (MLM): taking a sentence, the model randomly masks 15</span><span class="si">% o</span><span class="s2">f the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.&quot;</span>
    <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">(</span><span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">,</span> <span class="n">torchscript</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">cpu0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;bert_embeddings&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="p">))</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;bert_encoder&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">))</span>

    <span class="n">cpu0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">))</span>

<span class="c1">#</span>
<span class="c1"># Run inference pipeline on a Transformers model, enabling cpu fallback on unsupported ops</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_transformers_pipeline_fallback_inference</span><span class="p">():</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">BertTokenizer</span>

    <span class="n">compiler_cfg</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_get_global_compiler_config</span><span class="p">()</span> 

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">(</span><span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">)</span>
    <span class="n">input_sentence</span> <span class="o">=</span> <span class="s2">&quot;BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was pretrained with two objectives: Masked language modeling (MLM): taking a sentence, the model randomly masks 15</span><span class="si">% o</span><span class="s2">f the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.&quot;</span>
    <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">(</span><span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">,</span> <span class="n">torchscript</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;bert&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">))</span>

<span class="c1">#</span>
<span class="c1"># Run training through setup + manual loop of fwd/bwd/opt</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_manual_loop_with_cpu_fallback</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertForMaskedLM</span><span class="p">,</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertConfig</span> 

    <span class="n">config</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">(</span><span class="n">BertConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;bert&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">device_params</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;CEL&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()))</span>

    <span class="n">sample_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span> <span class="p">,)</span>
    <span class="n">sample_targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="p">,)</span>

    <span class="n">checkpoint_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span>
            <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span>
            <span class="n">sample_targets</span><span class="o">=</span><span class="n">sample_targets</span><span class="p">)</span>


    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">acc_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">128</span><span class="p">)))</span>
            <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">acc_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_optimizer</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Run training through run_training without placing on device</span>
<span class="c1"># Run training by placing on device first</span>
<span class="c1"># Repeated calls to run training</span>
<span class="c1"># Run training in concurrent mode, then push inputs afterwards</span>
<span class="c1"># Run training in concurrent mode, read checkpoints as they come out</span>
<span class="c1"># Run inference on multiple devices - combinations of cpu / tt device</span>

<span class="c1">#</span>
<span class="c1"># Run training through setup + manual loop of fwd/bwd/opt</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_manual_loop</span><span class="p">():</span>

    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">device_params</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()),</span>
            <span class="n">optimizer_f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">cpu1</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1loss&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>
    
    <span class="c1"># Compile &amp; initialize the pipeline for training, with given shapes</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">checkpoint_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span>
            <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">),</span>
            <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),))</span>


    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">acc_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
            <span class="n">cpu1</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">acc_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_optimizer</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Checkpoint: &quot;</span><span class="p">,</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">checkpoint_q</span><span class="p">))</span>

<span class="c1">#</span>
<span class="c1"># Run training through setup + manual loop of fwd/bwd, while copying final gradients</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_manual_loop_no_opt</span><span class="p">():</span>

    <span class="c1">#### Skip the test on golden. It should work, need to debug why it doesn&#39;t.</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
    <span class="k">if</span> <span class="s2">&quot;PYBUDA_DEVMODE&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">()</span>
    <span class="c1">####</span>

    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()))</span>
    <span class="n">cpu1</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1loss&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>
    
    <span class="c1"># Compile &amp; initialize the pipeline for training, with given shapes</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span>
            <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> 
            <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),))</span>

    <span class="n">steps</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">acc_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    
            <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
            <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
            <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

            <span class="n">cpu1</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">acc_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gradients on step &quot;</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="s2">&quot;: &quot;</span><span class="p">,</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">get_parameter_gradients</span><span class="p">())</span>

<span class="c1">#</span>
<span class="c1"># Run training and upload new weights from host</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_training_weight_update_on_host</span><span class="p">():</span>

    <span class="c1">#### Skip the test on golden. It should work, need to debug why it doesn&#39;t.</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
    <span class="k">if</span> <span class="s2">&quot;PYBUDA_DEVMODE&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">()</span>
    <span class="c1">####</span>

    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()))</span>
    <span class="n">cpu1</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1loss&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>
    
    <span class="c1"># Compile &amp; initialize the pipeline for training, with given shapes</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> 
            <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),))</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

        <span class="n">cpu1</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

    <span class="c1"># Run fwd/bwd to calculate parameter gradients</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Retrieve weights and gradients, and use host optimizer to update weights</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">get_parameter_gradients</span><span class="p">(</span><span class="n">tt0</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">get_parameter_checkpoint</span><span class="p">(</span><span class="n">tt0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">()</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Push new weights to the device</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">update_device_parameters</span><span class="p">(</span><span class="n">tt0</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1"># Run again with new weights</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="c1"># </span>
<span class="c1"># Run inference pipeline and provide mp queues for device-to-device data</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_inference_device_to_device_data</span><span class="p">():</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()))</span>
    <span class="n">cpu2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu2&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage2&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()))</span>
    
    <span class="c1"># Compile &amp; initialize the pipeline for inference, and provide d2d mp queues to store device-to-device data in for further analysis</span>
    <span class="n">tt0_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">cpu1_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">d2d_fwd_queues</span><span class="o">=</span><span class="p">[</span><span class="n">tt0_output_q</span><span class="p">,</span> <span class="n">cpu1_output_q</span><span class="p">],</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span> <span class="p">))</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run fwd</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Read d2d queues</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">tt0_output_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">cpu1_output_q</span><span class="p">))</span>

<span class="c1"># </span>
<span class="c1"># Run training pipeline and provide mp queues for device-to-device data</span>
<span class="c1">#</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_training_device_to_device_data</span><span class="p">():</span>
    
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">))</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu1&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage1&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModule</span><span class="p">()))</span>
    <span class="n">cpu2</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span><span class="s2">&quot;cpu2&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;stage2&quot;</span><span class="p">,</span> <span class="n">PyTorchTestModuleOneOut</span><span class="p">()))</span>
    <span class="n">cpu2</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1loss&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>
    
    <span class="c1"># Compile &amp; initialize the pipeline for inference, and provide d2d mp queues to store device-to-device data in for further analysis</span>
    <span class="n">tt0_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">cpu1_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">cpu1_bwd_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">cpu2_bwd_output_q</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span>
            <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">d2d_fwd_queues</span><span class="o">=</span><span class="p">[</span><span class="n">tt0_output_q</span><span class="p">,</span> <span class="n">cpu1_output_q</span><span class="p">],</span> 
            <span class="n">d2d_bwd_queues</span><span class="o">=</span><span class="p">[</span><span class="n">cpu1_bwd_output_q</span><span class="p">,</span> <span class="n">cpu2_bwd_output_q</span><span class="p">],</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> 
            <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),))</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

        <span class="n">cpu2</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

    <span class="c1"># Run fwd/bwd </span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">()</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">zero_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Read d2d queues</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">tt0_output_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">cpu1_output_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">cpu1_bwd_output_q</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_safe_read</span><span class="p">(</span><span class="n">cpu2_bwd_output_q</span><span class="p">))</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">get_parameter_gradients</span><span class="p">(</span><span class="n">tt0</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Override data formats</span>
<span class="c1">#</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_data_formats_input_override</span><span class="p">():</span>

    <span class="n">mod</span> <span class="o">=</span> <span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;mod&quot;</span><span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">mod</span><span class="p">)</span>

    <span class="c1"># Explicitly set data formats for parameters and inputs</span>
    <span class="n">mod</span><span class="o">.</span><span class="n">weights1</span><span class="o">.</span><span class="n">set_data_format</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16</span><span class="p">)</span>
    <span class="n">mod</span><span class="o">.</span><span class="n">weights2</span><span class="o">.</span><span class="n">set_data_format</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16</span><span class="p">)</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_data_formats_fp32_fallback</span><span class="p">():</span>
    
    <span class="c1"># On this device, fall back to Float16 wherever Float32 is used</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;mod&quot;</span><span class="p">),</span> <span class="n">fp32_fallback</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Float16</span><span class="p">)</span>

    <span class="c1"># Push Float32, which will be converted to Float16 due to fp32_fallback</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_data_formats_op_override</span><span class="p">():</span>
    
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;mod&quot;</span><span class="p">))</span>

    <span class="c1"># Use API to set manual data format override on an op</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">configure_mixed_precision</span><span class="p">(</span><span class="n">name_regex</span><span class="o">=</span><span class="s2">&quot;matmul1&quot;</span><span class="p">,</span> <span class="n">output_df</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">DataFormat</span><span class="o">.</span><span class="n">Bfp8_b</span><span class="p">)</span>
    
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TorchSchedulerWithWarmupAndDecay</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">torch_schedulers</span><span class="o">.</span><span class="n">TorchLearningRateScheduler</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch optimizer learning rate updated to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TestScheduler</span><span class="p">(</span><span class="n">LearningRateScheduler</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pybuda optimizer learning rate updated to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">get_pytorch_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">torch_scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">torch_scheduler</span> <span class="o">=</span> <span class="n">TorchSchedulerWithWarmupAndDecay</span><span class="p">(</span>
                    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
                <span class="p">)</span>
            
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">torch_scheduler</span>


<span class="c1"># Run the learning rate scheduler across 100 steps to</span>
<span class="c1"># show how optimizer learning rate gets updated</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_learning_rate_scheduler</span><span class="p">():</span>
            
    <span class="n">lr</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">device_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">TestScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
    
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
        <span class="s2">&quot;tt0&quot;</span><span class="p">,</span> 
        <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModuleOneOut</span><span class="p">(</span><span class="s2">&quot;stage0&quot;</span><span class="p">),</span> 
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span>
    <span class="p">)</span>
    <span class="n">cpu1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">CPUDevice</span><span class="p">(</span>
        <span class="s2">&quot;cpu1&quot;</span><span class="p">,</span>
        <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span>
            <span class="s2">&quot;stage1&quot;</span><span class="p">,</span>
            <span class="n">PyTorchTestModuleOneInputAndOneOut</span><span class="p">()</span>
        <span class="p">),</span>
        <span class="n">optimizer_f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span>
        <span class="n">scheduler_f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_pytorch_scheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">cpu1</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span>
        <span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">,</span>
            <span class="n">PyTorchLoss</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">sequential</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
            <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> 
            <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),),</span> <span class="n">_sequential</span><span class="o">=</span><span class="n">sequential</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">pybuda</span><span class="o">.</span><span class="n">run_schedulers</span><span class="p">(</span><span class="n">sequential</span><span class="p">)</span>
    
    
    
<span class="k">def</span><span class="w"> </span><span class="nf">test_specific_chip_id</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run inference on a specific chip on a multi-chip system</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_devices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">detect_available_devices</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">num_devices</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="s2">&quot;Need at least 2 devices to run chip-id test&quot;</span><span class="p">)</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Create a TT device, on last available chip</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">chip_ids</span><span class="o">=</span><span class="p">[</span><span class="n">num_devices</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Place a module on the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;last_chip&quot;</span><span class="p">))</span>

    <span class="c1"># Push intputs to the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run pipeline, and read the outputs</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_run_on_chip</span><span class="p">(</span><span class="n">chip_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>

    <span class="c1"># Each process needs to have its own temporary dir</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">set_configuration_options</span><span class="p">(</span><span class="n">backend_output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;tt_build/test_out_chip_</span><span class="si">{</span><span class="n">chip_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Create a TT device, on last available chip</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">chip_ids</span><span class="o">=</span><span class="p">[</span><span class="n">chip_id</span><span class="p">])</span>

    <span class="c1"># Place a module on the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chip_</span><span class="si">{</span><span class="n">chip_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="c1"># Push intputs to the device</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>

    <span class="c1"># Run pipeline, and read the outputs</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;From chip &quot;</span><span class="p">,</span> <span class="n">chip_id</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

    <span class="c1"># Clean up the process so we can end it cleanly</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">test_parallel_chips</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run different models on multiple chips at the same time</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="s2">&quot;Appears to hang now&quot;</span><span class="p">)</span>
    <span class="n">num_devices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">detect_available_devices</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">num_devices</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="s2">&quot;Need at least 2 devices to run parallel chip test&quot;</span><span class="p">)</span>

    <span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_devices</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">mp_context</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">_run_on_chip</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="p">,))</span>
        <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">procs</span><span class="p">):</span>
        <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_tti_inference_save_and_load</span><span class="p">():</span>
    <span class="n">available_devices</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">detect_available_devices</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">available_devices</span> <span class="ow">and</span> <span class="n">available_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">BackendDevice</span><span class="o">.</span><span class="n">Grayskull</span><span class="p">:</span>
        <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
            <span class="s2">&quot;tt0&quot;</span><span class="p">,</span>
            <span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Grayskull</span><span class="p">,</span>
            <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Golden</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
            <span class="s2">&quot;tt0&quot;</span><span class="p">,</span>
            <span class="n">arch</span><span class="o">=</span><span class="n">BackendDevice</span><span class="o">.</span><span class="n">Wormhole_B0</span><span class="p">,</span>
            <span class="n">devtype</span><span class="o">=</span><span class="n">BackendType</span><span class="o">.</span><span class="n">Golden</span><span class="p">,</span>
        <span class="p">)</span>


    <span class="n">module</span> <span class="o">=</span> <span class="n">PyBudaTestModule</span><span class="p">(</span><span class="s2">&quot;test_pybuda_module&quot;</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">place_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="c1"># Saving to Archive</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">device_img</span> <span class="o">=</span> <span class="n">tt0</span><span class="o">.</span><span class="n">compile_to_image</span><span class="p">(</span>
        <span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/test_tt0.tti&quot;</span><span class="p">,</span> 
        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">pybuda_reset</span><span class="p">()</span>  <span class="c1"># flush the global state that lingers around for test</span>

    <span class="c1"># Loading from Archive</span>
    <span class="n">tt1</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">img_path</span><span class="o">=</span><span class="s2">&quot;device_images/test_tt0.tti&quot;</span><span class="p">)</span>
    <span class="n">tt1</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
    <span class="n">output_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">_safe_read</span><span class="p">(</span><span class="n">output_q</span><span class="p">)</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;hoist_tms&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_nop_insertion_api</span><span class="p">(</span><span class="n">hoist_tms</span><span class="p">):</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestQueryKeyModule</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;query_key_module_hoist_tms_</span><span class="si">{</span><span class="n">hoist_tms</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="c1"># Use API to set manual data format override on an op</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">insert_nop</span><span class="p">(</span><span class="s2">&quot;mha_key&quot;</span><span class="p">,</span> <span class="s2">&quot;mha_as&quot;</span><span class="p">,</span> <span class="n">hoist_tms</span><span class="o">=</span><span class="n">hoist_tms</span><span class="p">)</span>
    <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">encoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">encoder_input</span><span class="p">))</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;hoist_tms&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_nop_fork_insertion_api</span><span class="p">(</span><span class="n">hoist_tms</span><span class="p">):</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestQueryKeyModule</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;forking_nop_insertion</span><span class="si">{</span><span class="n">hoist_tms</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="c1"># Use API to set manual data format override on an op</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">insert_nop</span><span class="p">(</span><span class="s2">&quot;encoder_input&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;mha_key&quot;</span><span class="p">,</span> <span class="s2">&quot;mha_query&quot;</span><span class="p">],</span> <span class="n">hoist_tms</span><span class="o">=</span><span class="n">hoist_tms</span><span class="p">)</span>
    <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">encoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">encoder_input</span><span class="p">))</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;hoist_tms&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_nop_daily_chain_insertion_api</span><span class="p">(</span><span class="n">hoist_tms</span><span class="p">):</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestForkWithThreeUsers</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;daisy_chain_nop_insertion</span><span class="si">{</span><span class="n">hoist_tms</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="c1"># Use API to set manual data format override on an op</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">insert_nop</span><span class="p">(</span><span class="s2">&quot;encoder_input&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;mm_a&quot;</span><span class="p">,</span> <span class="s2">&quot;mm_b&quot;</span><span class="p">,</span> <span class="s2">&quot;mm_c&quot;</span><span class="p">],</span> <span class="n">hoist_tms</span><span class="o">=</span><span class="n">hoist_tms</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">insert_nop</span><span class="p">(</span><span class="s2">&quot;buffer_0_encoder_input_mm_a&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;mm_b&quot;</span><span class="p">,</span> <span class="s2">&quot;mm_c&quot;</span><span class="p">],</span> <span class="n">hoist_tms</span><span class="o">=</span><span class="n">hoist_tms</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">insert_nop</span><span class="p">(</span><span class="s2">&quot;buffer_0_buffer_0_encoder_input_mm_a_mm_b&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;mm_c&quot;</span><span class="p">],</span> <span class="n">hoist_tms</span><span class="o">=</span><span class="n">hoist_tms</span><span class="p">)</span>
    <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">encoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">microbatch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">encoder_input</span><span class="p">))</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_dram_channel_override</span><span class="p">():</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span><span class="s2">&quot;tt0&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">PyBudaTestModule</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dram_channel_override&quot;</span><span class="p">))</span>

    <span class="c1"># Use API to set manual data format override on an op</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">override_dram_queue_placement</span><span class="p">(</span><span class="s2">&quot;e2e_matmul1_0&quot;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_epoch_break</span><span class="p">(</span><span class="s2">&quot;matmul2&quot;</span><span class="p">)</span>

    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">((</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">))</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="s2">&quot;mse&quot;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_loss_module_on_ttdevice</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">Lin</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Lin</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_linear</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Lin</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">tt0</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">TTDevice</span><span class="p">(</span>
        <span class="s2">&quot;tt0&quot;</span><span class="p">,</span>
        <span class="n">module</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;lin&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">),</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">pybuda</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">device_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;mse_loss&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tt0</span><span class="o">.</span><span class="n">place_loss_module</span><span class="p">(</span><span class="n">pybuda</span><span class="o">.</span><span class="n">PyTorchModule</span><span class="p">(</span><span class="s2">&quot;l1_loss&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()))</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Initialize pipeline</span>
    <span class="n">checkpoint_q</span> <span class="o">=</span> <span class="n">pybuda</span><span class="o">.</span><span class="n">initialize_pipeline</span><span class="p">(</span>
       <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
       <span class="n">sample_inputs</span><span class="o">=</span><span class="p">(</span><span class="n">inputs</span><span class="p">,),</span>
       <span class="n">sample_targets</span><span class="o">=</span><span class="p">(</span><span class="n">targets</span><span class="p">,)</span>
    <span class="p">)</span>

    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">tt0</span><span class="o">.</span><span class="n">push_to_target_inputs</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span><span class="n">input_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">zero_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pybuda</span><span class="o">.</span><span class="n">run_optimizer</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Introduction to PyBuda" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api.html" class="btn btn-neutral float-right" title="API Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Tenstorrent.
      <span class="lastupdated">Last updated on May 09, 2025.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: latest
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        
        <dl>
            <dt>Versions</dt>
            
            <dd><a href="https://tenstorrent.github.io/pybuda/versions/index.html">versions</a></dd>
            
        </dl>
        
        <br>
        </dl>
    </div>
</div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>